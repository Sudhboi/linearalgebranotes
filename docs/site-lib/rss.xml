<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[MATH2213]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>site-lib/media/favicon.png</url><title>MATH2213</title><link/></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Mon, 29 Dec 2025 06:29:54 GMT</lastBuildDate><atom:link href="site-lib/rss.xml" rel="self" type="application/rss+xml"/><pubDate>Mon, 29 Dec 2025 06:29:53 GMT</pubDate><ttl>60</ttl><dc:creator/><item><title><![CDATA[index]]></title><description><![CDATA[Welcome to my MATH2213 Notes! Please refresh the page if you suspect it is missing any notes.<a data-href="Systems of Linear Equations" href="systems-of-linear-equations.html" class="internal-link" target="_self" rel="noopener nofollow">Systems of Linear Equations</a><br><a data-href="Vector Spaces" href="allanglesnotes/vector-spaces.html" class="internal-link" target="_self" rel="noopener nofollow">Vector Spaces</a><br>
<a data-href="Lengths, Angles, Projections, Calculations" href="allanglesnotes/lengths,-angles,-projections,-calculations.html" class="internal-link" target="_self" rel="noopener nofollow">Lengths, Angles, Projections, Calculations</a>]]></description><link>index.html</link><guid isPermaLink="false">index.md</guid><pubDate>Mon, 29 Dec 2025 06:29:33 GMT</pubDate></item><item><title><![CDATA[Lengths, Angles, Projections, Calculations]]></title><description><![CDATA[Also sometimes called the scalar product.Type: Vector(a, n) -&gt; Vector(a, n) -&gt; a (Assuming type a is closed under multiplication)We can use this to calculate the length.This norm is called the modulus/length/norm. is a unit vector, and the process done above is called normalizing. We can now get the distance between two vectors and by taking .The dot product can also be written as follows -This gives us a nice formula for the angle between two vectors.The elements of a vector don't all have to be the same type. However, computing the dot product may not always be possible for such a vector.The dot product of two orthogonal vectors is 0. Orthogonal vectors are said to be maximally independent of each other. The dot product can also be used as a measure of correlation/similarity.The dot product is always . This can be seen by the following -where is the th element of the vector. This is why we can take square roots.Important Note:This is because we have not defined division. There are three ways this equation could be true, as is evident from the following rewritten equation. is orthogonal to .
We can also use dot products to find projections. Take a vector .This is also a measure of correlation. Now, how do we find projections of a vector onto a non-basis vector?Combining these, we get,An application of dot products can be seen in calculating work.We can now distribute the dot product over the sum. (It does that.)The terms in the brackets are just projections.A dot product is just an example of an inner product.All inner products must have the following properties -
The output must be a real number.
The inner product must be commutative
The inner product of the vector with itself must be .
The inner product should be linear.
These properties are slightly different when using complex numbers.]]></description><link>allanglesnotes/lengths,-angles,-projections,-calculations.html</link><guid isPermaLink="false">AllAnglesNotes/Lengths, Angles, Projections, Calculations.md</guid><pubDate>Mon, 29 Dec 2025 06:22:47 GMT</pubDate></item><item><title><![CDATA[Systems of Linear Equations]]></title><description><![CDATA[Below is an example of a system of linear equations.The solution set to the above system is . A system of linear equations
has exactly one solution,
has infinitely many solutions, or,
has no solution.
If the system has at least one solution, it is said to be consistent. Otherwise, it is inconsistent.Given the system,we can construct a coefficient matrix as follows -The augmented matrix, with the right hand sides of the equations, is given below.Theorem A function hsa a unique power series expansion centered at .
Corollary - No matter how you get it, the power series will be the same.We can use substitution. For example,for all .only for . So,true for all . So, this is the taylor series for .
Eg.Since coefficient for is 0. (We see that from the power series derived before). This means that if you get any power series, it has to be equal to the taylor series of the function.Warning:as , , We can show that Therefore, the taylor expansion,Take Taylor Polynomials , the error does not go to 0.Apparently Complex Analysis explains it very well. Here, the degree 0 coefficient is zero.Degree 0 is the term.Theorem: On the open interval of convergence of ,Example: and have the same interval of convergence. (Do the ratio test)]]></description><link>systems-of-linear-equations.html</link><guid isPermaLink="false">Systems of Linear Equations.md</guid><pubDate>Tue, 23 Dec 2025 20:09:05 GMT</pubDate></item></channel></rss>